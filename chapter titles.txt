
Part V — Structure & Constraints

18. Hierarchical & Goal‑Conditioned RL

Options & Skills

Subgoal Discovery

Goal‑Conditioned Policies

Hindsight Experience Replay (HER)

19. Offline & Batch RL

Off‑Policy Evaluation (IS, WIS, DR)

Batch‑Constrained Q‑Learning (BCQ)

BEAR & CQL

Distribution Shift & Conservatism

20. Safe & Risk‑Sensitive RL

Constrained MDPs

Risk Measures (CVaR)

Robust MDPs

Shielding & Safety‑Critical Evaluation

21. Multi‑Agent RL

Markov Games

Centralized Training, Decentralized Execution

Cooperation vs. Competition

Opponent Modeling & Equilibria

Part VI — Imitation, Preferences & LLMs

22. Imitation & Inverse RL

Behavior Cloning

DAgger & Dataset Aggregation

Maximum‑Entropy IRL

Adversarial Imitation (GAIL, AIRL)

23. Preference‑Based RL & Alignment

Reward Modeling from Human Feedback

RLHF with PPO

GRPO (Group Relative Policy Optimization)

Safety, Bias & Evaluation

Part VII — Applications (Beyond Robotics Emphasis)

24. Revenue & Pricing

Dynamic Pricing as Bandit/MDP

Contextual Pricing & Elasticity

Auction & Ad Bidding

Budget Pacing & Constraints

25. Operations & Supply Chain

Inventory Control

Routing & Dispatch

Queueing & Service Control

Energy & Demand Response

26. Recommendations & Personalization

Slate & Diversified Bandits

Long‑Horizon Engagement

Counterfactual Evaluation

Fairness & Exposure Control

27. Healthcare & Finance

Treatment Policy Optimization

Off‑Policy Safety

Portfolio Management & Execution

Risk & Regulation

28. Robotics & Control (Focused Overview)

Continuous Control Benchmarks

Sim2Real & Domain Randomization

Learning from Demonstrations

Safety in Physical Systems

Part VIII — Engineering & Production

29. Experimentation & Evaluation

Metrics & Confidence Intervals

Ablations & Hyperparameter Tuning

Statistical Significance

Reproducibility & Seeding

30. Systems, Scaling & Tooling

Vectorized Environments & Parallelism

Distributed Training & Rollouts

Replay Storage & Checkpointing

Monitoring & Dashboards

31. Deployment & Operations

Serving Policies Online

Guardrails, Kill‑Switches & Rollbacks

Drift Detection & Retraining

Human‑in‑the‑Loop

Part IX — Theory Deep Dives

32. Convergence & Stability

Projected Bellman Operator

Deadly Triad

Divergence Examples

Remedies & Constraints

33. Regret, PAC & Sample Complexity

Bandit Regret Bounds

PAC‑MDP & Optimism

Function Approximation Regret

Lower Bounds & Minimax

34. Stochastic Approximation & Natural Gradient

Robbins–Monro

Polyak–Ruppert Averaging

Fisher Information & Natural Gradient

Trust‑Region Connections

Part X — Projects & Roadmaps

35. Hands‑On Projects & Templates

Pricing Simulator

Inventory Sandbox

Ad Auction Lab

Gridworlds & Mazes

36. Reading Lists & Research Roadmaps

Classic Texts & Courses

Key Papers by Topic

Open Problems & Trends


Community & Conferences

